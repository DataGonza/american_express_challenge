{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd07d3bf-20a5-4def-965a-ecc633fc939b",
   "metadata": {},
   "source": [
    "# Preparating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eaf783d-eb9e-4065-9e31-db4d43f2acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from multiprocessing import  Pool\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e246f04b-6a1d-4670-983f-7231a0b33234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import variables of all process\n",
    "sample_frac = 0.25\n",
    "frac_nan_values = 0.05\n",
    "\n",
    "#some important dicts\n",
    "map_D63 = dict(zip(['CR', 'CO', 'CL', 'XL', 'XZ', 'XM'], range(6)))\n",
    "map_D64 = dict(zip(['O', 'R', np.nan, 'U', '-1'], [0, 1, np.nan, 2, 3]))\n",
    "columns_dtype = {'B_31' : 'int8', **json.load(open('columns_map.json'))}\n",
    "columns_to_drop = ['S_3', 'D_42', 'D_43', 'D_46', 'D_48', 'D_49', 'D_50', 'D_53',\n",
    "                   'S_7', 'D_56', 'S_9', 'D_62', 'B_17', 'D_66', 'D_73', 'D_76',\n",
    "                   'D_77', 'R_9', 'D_82', 'B_29', 'D_87', 'D_88', 'D_105', 'D_106',\n",
    "                   'R_26', 'R_27', 'D_108', 'D_110', 'D_111', 'B_39', 'S_27', 'B_42',\n",
    "                   'D_132', 'D_134', 'D_135', 'D_136', 'D_137', 'D_138', 'D_142','S_2']\n",
    "\n",
    "\n",
    "# Reading data in chunks\n",
    "all_columns = list(pd.read_csv('C:/Users/DavidG/Documents/american_express_data/train_data.csv', nrows =1))\n",
    "columns_to_read = np.setdiff1d(all_columns, columns_to_drop)\n",
    "train_result = pd.read_csv('C:/Users/DavidG/Documents/american_express_data/train_labels.csv', dtype = {'target': 'int8'}) # Read the result of train data\n",
    "\n",
    "train_partitions = np.array_split(train_result.sample(frac = 1, random_state = 12345), int(1/sample_frac))\n",
    "\n",
    "\n",
    "#print(\"Fraction of 1 in the complete dataset is {}\".format(sum(train_result['target'])/len(train_result))) # Showing the fraction of 1 in the all data\n",
    "#print(\"Fraction of 1 in the sample dataset is {}\".format(sum(train_result_sample['target'])/len(train_result_sample))) # Showing the fraction of 1 in the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d058e693-87e8-4a97-ba8b-52a1c4d683cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready the lecture of 0 partition\n",
      "Ready apply of 0 partition\n",
      "Ready add n values of 0 partition\n",
      "Ready m_values of 0 partition\n",
      "Ready other features of 0 partition and save\n",
      "Ready the lecture of 1 partition\n",
      "Ready apply of 1 partition\n",
      "Ready add n values of 1 partition\n",
      "Ready m_values of 1 partition\n",
      "Ready other features of 1 partition and save\n",
      "Ready the lecture of 2 partition\n",
      "Ready apply of 2 partition\n",
      "Ready add n values of 2 partition\n",
      "Ready m_values of 2 partition\n",
      "Ready other features of 2 partition and save\n",
      "Ready the lecture of 3 partition\n",
      "Ready apply of 3 partition\n",
      "Ready add n values of 3 partition\n",
      "Ready m_values of 3 partition\n",
      "Ready other features of 3 partition and save\n"
     ]
    }
   ],
   "source": [
    "n = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])\n",
    "div_val = n*((n*n).cumsum()) - (n.cumsum())**2\n",
    "div = dict(zip(n, div_val))\n",
    "div = {0:np.nan, **div}\n",
    "div[1] = np.nan\n",
    "sum_val = dict(zip(n, n.cumsum()))\n",
    "sum_val = {0:np.nan, **sum_val}\n",
    "\n",
    "for k, partition in enumerate(train_partitions):\n",
    "    train_data = pd.read_csv('C:/Users/DavidG/Documents/american_express_data/train_data.csv', chunksize = 500000, dtype = columns_dtype, usecols = columns_to_read)\n",
    "    train_result_sample = partition\n",
    "    chunk_list = []\n",
    "    for chunk in train_data:\n",
    "        chunk_list.append(pd.merge(train_result_sample, chunk, how = 'inner', on = 'customer_ID'))\n",
    "\n",
    "    train_data_sample = pd.concat(chunk_list)\n",
    "\n",
    "\n",
    "    del chunk_list\n",
    "    print('Ready the lecture of {} partition'.format(k))\n",
    "    \n",
    "    \n",
    "    train_data_sample['D_63'] = train_data_sample.apply(lambda x: map_D63[x['D_63']], axis = 1)\n",
    "    train_data_sample['D_64'] = train_data_sample.apply(lambda x: map_D64[x['D_64']], axis = 1)\n",
    "    print('Ready apply of {} partition'.format(k))\n",
    "    \n",
    "    train_data_sample.reset_index(drop = True, inplace = True)\n",
    "    train_data_sample['n'] = np.ones(len(train_data_sample), dtype = 'int8')\n",
    "    j = 1\n",
    "    for i in range(1, len(train_data_sample)):\n",
    "        if train_data_sample.loc[(i-1, 'customer_ID')] == train_data_sample.loc[(i, 'customer_ID')]:\n",
    "            j += 1\n",
    "        else:\n",
    "            j = 1\n",
    "        train_data_sample.loc[(i, 'n')] = j\n",
    "    cont_pd = train_data_sample.drop(['target', 'n'], axis = 1).groupby('customer_ID').count()\n",
    "    print('Ready add n values of {} partition'.format(k))\n",
    "    \n",
    "    # m values\n",
    "    m_values = train_data_sample.drop(['target', 'n', 'customer_ID'], axis = 1).multiply(train_data_sample['n'], axis = 0)\n",
    "    m_values = m_values.astype('float32')\n",
    "    m_values = pd.concat([m_values, train_data_sample['customer_ID']], axis = 1)\n",
    "    m_values = m_values.groupby('customer_ID').sum() * cont_pd\n",
    "    m_values = m_values + cont_pd.applymap(lambda x: -sum_val[x])*train_data_sample.drop(['target', 'n'], axis = 1).groupby('customer_ID').prod()\n",
    "    m_values = m_values.astype('float32')\n",
    "    m_values = m_values / cont_pd.applymap(lambda x: div[x])\n",
    "    m_values = m_values.astype('float32')\n",
    "    print('Ready m_values of {} partition'.format(k))\n",
    "    \n",
    "    # Other features\n",
    "    X_train = train_data_sample.drop(['target'], axis = 1).groupby('customer_ID').agg([np.mean, np.max, np.min, np.std])\n",
    "    X_train = pd.DataFrame(data = X_train.values.astype('float32'), index = X_train.index, columns = [x[0] + '_' + x[1] for x in X_train.columns])\n",
    "    X_train = pd.merge(X_train, m_values, how = 'inner', left_index = True, right_index = True)\n",
    "    final_data_dropna = pd.merge(X_train.dropna(), train_result_sample, on = 'customer_ID', how = 'inner')\n",
    "    final_data_fillna = pd.merge(X_train.fillna(X_train.mean()), train_result_sample, on = 'customer_ID', how = 'inner')\n",
    "    final_data_dropna.to_parquet('C:/Users/DavidG/Documents/american_express_data/dropna_data_{}.parquet'.format(k))\n",
    "    final_data_fillna.to_parquet('C:/Users/DavidG/Documents/american_express_data/fillna_data_{}.parquet'.format(k))\n",
    "    print('Ready other features of {} partition and save'.format(k))\n",
    "    \n",
    "    # Eliminate variables\n",
    "    del m_values\n",
    "    del X_train\n",
    "    del train_data_sample\n",
    "    del train_result_sample\n",
    "    del cont_pd\n",
    "    del final_data_dropna\n",
    "    del final_data_fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8792f096-beee-4928-880b-23b1c4cb9885",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13])\n",
    "div_val = n*((n*n).cumsum()) - (n.cumsum())**2\n",
    "div = dict(zip(n, div_val))\n",
    "div = {0:np.nan, **div}\n",
    "div[1] = np.nan\n",
    "sum_val = dict(zip(n, n.cumsum()))\n",
    "sum_val = {0:np.nan, **sum_val}\n",
    "train_data_sample.reset_index(drop = True, inplace = True)\n",
    "train_data_sample['n'] = np.ones(len(train_data_sample), dtype = 'int8')\n",
    "j = 1\n",
    "for i in range(1, len(train_data_sample)):\n",
    "    if train_data_sample.loc[(i-1, 'customer_ID')] == train_data_sample.loc[(i, 'customer_ID')]:\n",
    "        j += 1\n",
    "    else:\n",
    "        j = 1\n",
    "    train_data_sample.loc[(i, 'n')] = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bde47763-f051-4c03-8bd3-2b63a09d5241",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_pd = train_data_sample.drop(['target', 'n'], axis = 1).groupby('customer_ID').count()\n",
    "\n",
    "# m values\n",
    "m_values = train_data_sample.drop(['target', 'n', 'customer_ID'], axis = 1).multiply(train_data_sample['n'], axis = 0)\n",
    "m_values = m_values.astype('float32')\n",
    "m_values = pd.concat([m_values, train_data_sample['customer_ID']], axis = 1)\n",
    "m_values = m_values.groupby('customer_ID').sum() * cont_pd\n",
    "m_values = m_values + cont_pd.applymap(lambda x: -sum_val[x])*train_data_sample.drop(['target', 'n'], axis = 1).groupby('customer_ID').prod()\n",
    "m_values = m_values.astype('float32')\n",
    "m_values = m_values / cont_pd.applymap(lambda x: div[x])\n",
    "m_values = m_values.astype('float32')\n",
    "\n",
    "# Other features\n",
    "X_train = train_data_sample.drop(['target'], axis = 1).groupby('customer_ID').agg([np.mean, np.max, np.min, np.std])\n",
    "X_train = pd.DataFrame(data = X_train.values.astype('float32'), index = X_train.index, columns = [x[0] + '_' + x[1] for x in X_train.columns])\n",
    "X_train = pd.merge(X_train, m_values, how = 'inner', left_index = True, right_index = True)\n",
    "final_data_dropna = pd.merge(X_train.dropna(), train_result_sample, on = 'customer_ID', how = 'inner')\n",
    "final_data_fillna = pd.merge(X_train.fillna(X_train.mean()), train_result_sample, on = 'customer_ID', how = 'inner')\n",
    "\n",
    "# Eliminate variables\n",
    "del m_values\n",
    "del X_train\n",
    "del train_data_sample\n",
    "del train_result_sample\n",
    "del cont_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d311359b-e4ce-46f7-aca6-001127f78d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section only for select columns too empty\n",
    "#columns = []\n",
    "#nan_values = []\n",
    "#for column in train_data_sample.columns:\n",
    "#    try:\n",
    "#        nan_value = np.sum(np.isnan(train_data_sample[column]))\n",
    "#        if nan_value != 0:\n",
    "#            columns.append(column)\n",
    "#            nan_values.append(nan_value)\n",
    "#    except:\n",
    "        ;\n",
    "#columns_with_nan = pd.DataFrame(data = nan_values, index = columns)\n",
    "#columns_to_drop = columns_with_nan[columns_with_nan[0] > len(train_data_sample)*frac_nan_values].index.values\n",
    "#train_data_sample.drop(labels = columns_to_drop, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac69c42c-ff07-4d0e-81be-376876f788f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = final_data_fillna.drop(['customer_ID', 'target'], axis = 1)\n",
    "y_train = final_data_fillna['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbdc4579-ce86-4006-8a67-e18b86fd04c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "    print(\"g value is {} and d value is {}\".format(g, d))\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e01399d-58ba-4065-8d0a-b13267d5e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(X_train, y_train, random_state=0) \n",
    "sc = StandardScaler() \n",
    "x_train_2 = sc.fit_transform(x_train_2)\n",
    "x_test_2 = sc.transform(x_test_2) \n",
    "#pca = PCA(n_components = 60).fit(x_train_2)\n",
    "#x_train_2 = pca.transform(x_train_2)\n",
    "#x_test_2 = pca.transform(x_test_2)\n",
    "#mds = MDS(n_components = 20)\n",
    "#x_train_2 = mds.fit_transform(x_train_2)\n",
    "#x_test_2 = mds.transform(x_test_2)\n",
    "\n",
    "#tsne = TSNE(random_state = 0)\n",
    "\n",
    "#x_train_2 = tsne.fit_transform(x_train_2)\n",
    "#x_test_2 = tsne.transform(x_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3909504-a9bc-46ef-9ce1-ac114b33f4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;auc&#x27;, gamma=0.1, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.2, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=&#x27;auc&#x27;, gamma=0.1, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.2, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric='auc', gamma=0.1, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.2, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(objective = 'binary:logistic', seed = 42, \n",
    "                           eval_metric = 'auc', max_depth = 3, learning_rate = 0.2, gamma = 0.1)\n",
    "xgb_clf.fit(x_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad37db95-9fc7-45c2-9bbc-7bf5f50b49ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "Precision: 0.79\n",
      "Recall: 0.78\n",
      "F1: 0.79\n",
      "g value is 0.9047781436540279 and d value is 0.5964209401709402\n",
      "0.750599541912484\n"
     ]
    }
   ],
   "source": [
    "y_predict = xgb_clf.predict(x_test_2)\n",
    "y_predict_proba = xgb_clf.predict_proba(x_test_2)[:,1]\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test_2, y_predict)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test_2, y_predict)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test_2, y_predict)))\n",
    "print('F1: {:.2f}'.format(f1_score(y_test_2, y_predict)))\n",
    "print(amex_metric(pd.DataFrame(y_test_2), pd.DataFrame(y_predict_proba, index = y_test_2.index, columns = ['prediction'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dae93901-81f8-460b-bd48-d2c2dec43b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEWCAYAAACjYXoKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA3LElEQVR4nO3deZgU5dX+8e+toAJGFsEN3HAAWUSi4PLGEFwGCBrURCMkcUNFUaPxFzUa44J5o0Rj3NCgQQSiQFwQeA0CBkWTsAUUkEVEAyqLGllUxoXt/P6omqGnp2G6pqe7ipnzua6+7K71HpV56Ko655GZ4ZxzzuVit7gDOOec2/X5YOKccy5nPpg455zLmQ8mzjnncuaDiXPOuZz5YOKccy5nPpg4lyNJv5Y0NO4czsVJXmfi4iRpBbA/sDVlcWszW53jMS81s7/nlm7XI+kOoMjMfhZ3Fle7+DcTlwQ/MLO9U15VHkiqg6Q6cZ6/qnbV3K5m8MHEJZKkhpKekLRG0ipJ/ytp93DdEZJekbRW0qeSnpbUKFz3F+AQ4P8kbZR0o6RuklamHX+FpNPC93dIek7SU5I+By7a2fkzZL1D0lPh+8MkmaSLJX0oab2kKyR1kbRA0gZJg1P2vUjSvyQNlvSZpLclnZqy/iBJEyStk/SupMvSzpua+wrg18B54c8+P9zuYklLJH0h6T+SLk85RjdJKyX9UtIn4c97ccr6epLuk/R+mO+fkuqF606QND38meZL6laF/9SuhvDBxCXVcGALUAR8G+gOXBquE3A3cBDQFjgYuAPAzM4HPmD7t517sjzfmcBzQCPg6UrOn43jgVbAecADwC3AaUB74MeSvpe27XtAU+B2YKykJuG6McDK8Gc9B7hL0ik7yP0EcBfw1/BnPzrc5hPgDGAf4GLgfknHpBzjAKAh0By4BHhEUuNw3R+AY4H/AZoANwLbJDUH/gb8b7j8euB5Sc0i/DtyNYgPJi4JxoV/u90gaZyk/YFewC/MrMTMPgHuB/oAmNm7ZvaymX1jZv8F/gh8b8eHz8oMMxtnZtsIfunu8PxZ+q2ZfW1mU4ASYLSZfWJmq4B/EAxQpT4BHjCzzWb2V2ApcLqkg4HvAL8KjzUPGApckCm3mX2VKYiZ/c3M3rPAa8AU4Lspm2wG7gzPPxHYCLSRtBvQD7jWzFaZ2VYzm25m3wA/Ayaa2cTw3C8Dc8J/b64W8musLgnOSr1ZLuk4oC6wRlLp4t2AD8P1+wMPEvxC/Fa4bn2OGT5MeX/ozs6fpY9T3n+V4fPeKZ9XWfknYd4n+CZyELDOzL5IW9d5B7kzkvR9gm88rQl+jvrAWymbrDWzLSmfvwzzNQX2IvjWlO5Q4FxJP0hZVhd4tbI8rmbywcQl0YfAN0DTtF9ype4CDDjKzNZJOgsYnLI+/RHFEoJfoACE9z7SL8ek7lPZ+atbc0lKGVAOASYAq4Emkr6VMqAcAqxK2Tf9Zy33WdKewPME32bGm9lmSeMILhVW5lPga+AIYH7aug+Bv5jZZRX2crWSX+ZyiWNmawguxdwnaR9Ju4U33UsvZX2L4FLMZ+G1+xvSDvEx0DLl8zvAXpJOl1QX+A2wZw7nr277AddIqivpXIL7QBPN7ENgOnC3pL0kdSS4p/HUTo71MXBYeIkKYA+Cn/W/wJbwW0r3bEKFl/yGAX8MHwTYXdKJ4QD1FPADST3C5XuFN/NbRP/xXU3gg4lLqgsIfhEuJriE9RxwYLhuIHAM8BnBTeCxafveDfwmvAdzvZl9BlxJcL9hFcE3lZXs3M7OX91mEdys/xT4HXCOma0N1/UFDiP4lvICcHsl9TPPhv9cK+mN8BvNNcAzBD/HTwi+9WTreoJLYv8G1gG/B3YLB7ozCZ4e+y/BN5Ub8N8ptZYXLToXI0kXERRYnhR3Fudy4X+LcM45lzMfTJxzzuXML3M555zLmX8zcc45l7MaVWfSqFEjKyoqijtGBSUlJTRo0CDuGBV4rmg8VzSeK5o4c82dO/dTM8utFY6Z1ZhX69atLYleffXVuCNk5Lmi8VzReK5o4swFzLEcf//6ZS7nnHM588HEOedcznwwcc45lzMfTJxzzuXMBxPnnHM588HEOedqoH79+rHffvvRoUOHcssffvhhjjzySNq3b8+NN96YcV9JPSUtDaeKvimb8yVqMJF0TThX9dOSHgp/kAVpU4w655yrxEUXXcSkSZPKLXv11VcZP3488+fPZ9GiRVx//fUV9gvn+3kE+D7QDugrqV1l50vUYELQJryYYA7uVuGrP/CnOEM559yupmvXrjRp0qTcsj/96U/cdNNN7LlnMJ3Pfvvtl2nX44B3zew/ZrYJGEMw3cBOJaYCXtIQggmNXiKYXvSisJhmpqRGkg60YNKiHfpq81YOu+lvBUgbzS+P2sJFnitrnisazxVNUnMN75n/6vd33nmHf/zjH9xyyy3stdde/OEPf6BLly7pmzWn/HTQK4HjKzt2YgYTM7tCUk/gZGA4FX+Y5kCFwURSf4JvLzRt2ozbjirELKvR7F8v+B84aTxXNJ4rGs8VzcaNG5k2bVq1HvOjjz6ipKSk7LifffYZb731FoMGDeLtt9+md+/ejBo1qnpOlmsJfXW+gBVAU+BF4KSU5VOBzpXt7+1UovFc0XiuaDxXNPnItXz5cmvfvn3Z5x49etgrr7xS9rlly5b2ySeflGunApwITE75fDNws1Xy+zdp90xKrQIOTvncIlzmnHOuis466yxeffVVILjktWnTJpo2bZq+2b+BVpIOl7QH0IcspnpO6mAyAbhAgROAz6yS+yXOOee269u3LyeeeCJLly6lRYsWPPHEE/Tr14///Oc/dOjQgT59+jBixAgkAdSVNBHAzLYAVwOTgSXAM2a2qLLzJeaeSZqJQC/gXeBL4OJ44zjn3K5l9OjRGZc/9dRTmRZvNrNepR/MbCLB7+GsJWowMbPDUj5eFVcO55xz0ST1MpdzztU6marW77jjDpo3b06nTp3o1KkTEydm/sIwadIk2rRpQ1FREYMGDSpU5DKJGkxSKuBXSfpM0rzwdVvc2ZxzLt8yVa0DXHfddcybN4958+bRq1evCuu3bt3KVVddxUsvvcTixYsZPXo0ixcvLkTkMom6zEVQAX8aUARcb2ZnxJzHOecKpmvXrqxYsSLyfrNnz6aoqIiWLVsC0KdPH8aPH0+7dpV2Qak2iRlM0irgh1XlGF4BH43nisZzRVMbcq0YdHq1HKcygwcPZuTIkXTu3Jn77ruPxo0bl1u/atUqDj54ezVFixYtmDVrVkGylVJYlJIIklYAnYEOwPMEle+rCb6lZHw0La0C/tjbHvhzYcJGsH89+PiruFNU5Lmi8VzR1IZcRzVvWD0HIqiA33vvvfnoo4+4+eabefLJJwFYt24dDRs2RBLDhg1j7dq1/OpXvyq372uvvcbs2bO54YYbAJgyZQpLlizh2muvzercJ5988lwz65zTD1BZVWMhX2yvgN8H2Dtc1gtYls3+XgEfjeeKxnNF47miKc2VXrWeakfrpk+fbt27dy/7fNddd9ldd92V9blJqYCv6itRN+BLmdnnZrYxfD+RoKCmQpmmc87VdGvWbK/XfuGFFyrMTwLQpUsXli1bxvLly9m0aRNjxoyhd+/ehYyZnHsmqSQdAHxsZibpOIKnztbGHMs55/Kqb9++TJs2jU8//ZQWLVowcOBApk2bxrx585DEYYcdxmOPPQbA6tWrufTSS5k4cSJ16tRh8ODB9OjRg61bt9KvXz/at29f0OyJHEyAc4ABkrYAXwF9wq9izjlXY2WqWr/kkksybnvQQQeVqznp1atXxseGCyVRg4ltr4AfHL6cc87tAhJ5z8Q55/IpU6X5rbfeSseOHenUqRPdu3dn9erVGfcdMWIErVq1olWrVowYMaJQkRMvUYNJSgW8hXO/vyVpuqSj487mnKs5MlWa33DDDSxYsIB58+ZxxhlncOedd1bYb926dQwcOJBZs2Yxe/ZsBg4cyPr16wsVO9ESNZiwfQ747wDfM7OjgN8Cj8eayjlXo2SaH32fffYpe19SUlLamr2cyZMnU1xcTJMmTWjcuDHFxcUZ25/URom5Z5JeAW9m08NVMwkmx6qUV8BH47mi8VzR7IqV5rfccgsjR46kYcOGZZNIpcpUab5qlc/bBwmtgDezT1OWXQ8caWaX7mAfr4CvIs8VjeeKZlerNE/19NNPs2nTJi6+uPxUSn/961/ZtGkT559/PgAjR45kzz335Lzzzqu2XHGosRXwKZ9PJpjpa99s9vcK+Gg8VzSeK5qk59pZpfn777+fcd2oUaOsf//+ZZ/79+9vo0aNqtZccaCmVsADSOoIDAXONDMvWHTO5dWyZcvK3o8fP54jjzyywjY9evRgypQprF+/nvXr1zNlyhR69OhRyJiJlZh7JqkkHQKMBc43s3fizuOcq1kyVZpPnDiRpUuXsttuu3HooYcyZMgQAObMmcOQIUMYOnQoTZo04dZbb6VLly4A3HbbbRVu5NdWiRxMgNuAfYFHwycqtliu1/Occy4UpdK8c+fODB06tOxzv3796NevX96y7aoSNZjY9gr4S8OXc865XUBi75k455zbdfhg4pzbJWRqgXLDDTdw5JFH0rFjR84++2w2bNiQcd9JkybRpk0bioqKGDVqVIES1y55HUxS2qM8LambpHmSFkl6LWWbnpKWSnpX0k0ZjvGQpI35zOmcS75MLVCKi4tZuHAhCxYsoHXr1tx9990V9tu6dStXXXUVL730EosXL2bq1KksXry4ULFrjXx/Myltj3IV8CjQ28zaA+cCSNodeAT4PtAO6CupXenOkjoDjdMP6pyrfTK1QOnevTt16gS3fk844QRWrlxZYb/Zs2dTVFREy5Yt2WOPPTjllFMYP358QTLXJnm7AZ/WHmUMMNbMPgAws0/CzY4D3jWz/4T7jAHOBBaHA829wE+As7M5p7dTicZzReO5ohnes0FBzzds2LCMlejpLVCaNWvmLVDyIG+DiZldIaknQRX7bwim3p0GfAt40MxGAs2BD1N2WwkcH76/GphgZmsyNVwrldZOhduO2lLdP0rO9q8X/IFPGs8VjeeKZuPGjUybNq1aj/nRRx9RUlJS4bhPPfUUGzZsoHnz5hXWLVq0iDVr1pQt//rrr1m1alW1Z8tVPv59FVSuJfQ7exG2RyGY6Gom0CD8vAxoTTCj4tCU7c8Ptz0I+CdQJ1y+MZvzeTuVaDxXNJ4rmnzkytQC5cknn7QTTjjBSkpKMu4zffp06969e9nnSy+91O66665qz5Yrb6eSnZXAZDMrsaCJ4+vA0cAq4OCU7VqEy74NFAHvhs0f60t6t0BZnXO7iEmTJnHPPfcwYcIE6tevn3GbLl26sGzZMpYvX86mTZt45ZVX6N27d4GT1nyFGkzGAydJqiOpPsGlrCXAv4FWkg6XtAfQh+DS1t/M7AAzO8yCQsYvzayoQFmdcwnUt29fTjzxRJYuXUqLFi144oknuPrqq/niiy8oLi6mU6dOXHHFFQCsXr26bD70OnXqMHjwYHr06EHbtm05+eSTad++fZw/So1UkAp4M1siaRKwANhGcGlrIYCkq4HJwO4E85gsKkQm59yuJUoLlIMOOoiJEyeWfe7Vq1fZ4LJL35dIsLwOJra9PQpmdi/B01np20wEJqYvT9smnib/zjnnsuIV8M65vMlUtf7ss8/Svn17dtttN+bMmbPDfVOr1gcNGlSIuC4Hia2Al3R1uMwkNc1nTudcfmSqWu/QoQNjx46la9euO9wvvWp99OjRXrWecPm+Z3IlcBqwEZgO9DSzDyTtB+Uq4IsJnvj6t6QJZrYY+BfwIjAtzxmdc3nStWtXVqxYUW5Z27ZtK90vtWodoE+fPowfP5527dpVsqeLS2Ir4M3szXBZ1uf0CvhoPFc0tSHXikGnV8txcpVetd6iRQtmzZoVYyJXmSRXwGfFK+CrznNFUxtyVeeTTqUV3TuqWt+wYQNz585l48aKfVzTq9aXLFlSbVXrSa00T2qubBVqcqw6wLHAqUA9YIakmdVxYDN7HHgcoE2bNvbzn55ZHYetVtOmTePH3brFHaMCzxWN54pm2rRpdOvWjRUrVtCgQQO6pWVs1KgRxx57LJ07V5xEdc8992T69Oll+8yYMYPjjjuuwjFyyZU0Sc2VraRWwDvnarH0qvUxY8Z41XrCJbICvkCZnHN5lqlq/YUXXqBFixbMmDGD008/nR49egA7r1r/8Y9/7FXrCZfYCnhJ1wA3AgcACyRNNDOfF965XUimqnWAs8+uOKvEzqrWXfIltgLezB4CHspnPuecc9XDK+Cdc+Vkqlpft24dxcXFtGrViuLiYtavX59x3xEjRtCqVStatWpVoVjR1WxJroB/QtJ8SQskPSfJ+3M5VwCZqtYHDRrEqaeeyrJlyzj11FMztjdZt24dAwcOZNasWcyePZuRI0fucNBxNU+S54C/zsyONrOOwAcEMy865/Is01zr48eP58ILLwTgwgsvZNy4cRX2mzx5MsXFxTRp0oTGjRtz7LHH+reTWiTJFfCfh8tEUJtilZ3TK+Cj8VzRJDVXIeZa//jjjznwwAMBOOCAA/j4448rbONzrdduia6Al/Qk0AtYDPwy03m8Ar7qPFc0Sc1ViLnWt2zZUu4cW7durXDO9957j02bNpUt37RpE++9917iqrqTWmme1FzZSnQFvJldHF4Kexg4D3gywzZlFfCHtCyy+94q1I+UvV8etQXPlT3PFc3wnhWry3OVXrXevHlz2rRpw4EHHsiaNWs46KCDKpyztP1J6fL77ruP008/PXFV3UmtNE9qrmwV6k/GSmCtmZUAJZJKK+BXUkkFvJltDS9/3UiGwSRVvbq7szQhjepSTZs2jRU/7RZ3jAo8VzRJzpVvvXv3ZsSIEdx0002MGDGCM8+s2LaoR48e/PrXvy676T5nzhxGjBiR92wuGRJZAa9AEZTdM+kNvF2grM7Vapmq1m+66SZefvllWrVqxd///nduuil48HLOnDlcemlQS9ykSRNuvfVWunTpQpcuXbjgggsq3Mh3NVciK+Al7QaMkLQPIGA+MKAQWZ2r7XZUtT516tQKyzp37szQoUPLPvfr149+/foBPtd6bZPICngz2wZ8J5/ZnHPOVR+vgHfOOZczH0yci9H9999P+/bt6dChA3379uXrr78ut/6bb77hvPPOo6ioiOOPP77CFLjOJUUsg0lKm5WSsMXKPEkLJW2V1CTc5rqw9cpCSaMl7RVHVufyZdWqVTz00EPMmTOHhQsXsnXrVsaMGVNumyeeeILGjRvz7rvvct111/GrX/0qprTO7Vxc30yuBIrNrIGZdTKzTsDNwGtmtk5Sc+AaoLOZdSC4Od8npqzO5c2WLVv46quv2LJlC19++SUHHXRQufWpbUzOOeccpk6dilmlzSCcK7iCV2CltlmRNMzM7g9X9QVSHyOpA9STtBmoD6yu7NjeTiUazxVNdbctad68Oddffz2HHHII9erVo3v37nTv3r3cNqktSurUqUPDhg1Zu3YtTZs2rdYszuWq4INJapuVcApfwtqTnoTNHM1slaQ/EDR4/AqYYmZTMh3P26lUneeKprrbXXzxxReMGDGCp556ir333ps77riDW265heLi4rJtSkpKmDFjBs2aNQPg66+/5l//+hcNGzbMW67q4rmiSWqurJlZwV/ACqBpyufzgP9L+dwYeAVoBtQFxgE/q+y4rVu3tiR69dVX446QkeeKprpzPfPMM9avX7+yzyNGjLABAwaU26Z79+42ffp0MzPbvHmz7bvvvrZt27a85qouniuaOHMBcyzH3+tJeZqrD+UvcZ0GLDez/5rZZmAs8D+xJHMuTw455BBmzpzJl19+iZkxdepU2rZtW26b0jYmAM899xynnHIKQVMI55Il9sFEUkPgewQtV0p9AJwgqX7YTuVUgvYrztUYxx9/POeccw7HHHMMRx11FNu2baN///7cdtttTJgwAYBLLrmEtWvXUlRUxB//+MeMk1I5lwRJaIF6NsE9kZLSBWY2S9JzwBvAFuBNws7AztUkAwcOZODAgeWW3XnnnWXv99prL5599tlCx3IuslgGEyvfZmU4MDzDNrcDtxcslHPOuSqL/TKXc7WZV8C7miLuCvj1khaEFfBzJJ2Uss3WlOr4CXHkdC6fvALe1SRx3TO5kuCJrQ1AiZmZpI7AM8CR4TZfWVAZ71yNVVoBX7du3R1WwN9xxx1AUAF/9dVXY2b+RJdLnFgr4AnmLymtgG8A5NQnwivgo/Fc0XgFvHM7FnsFvKSzgbuB/YDUOXf3kjSH4GmuQWY2LtPxvAK+6jxXNF4BH43niiapubKWa9VjVV6kVcCHy7oCf0/53Dz8Z8tw+yMqO65XwEfjuaLxCvhoPFc0XgFfTczsdaClpKbh51XhP/8DTAO+HV8656qfV8C7miTWwURSUVjhjqRjgD2BtZIaS9ozXN6UYArfxfElda76eQW8q0niroD/EXBB2Gb+K+A8MzNJbYHHJG0jGPAGmZkPJq7G8Qp4V1PEXQH/+/CVvn46cFQhMznnnKu6xNwzca428gp4V1NkNZhIOiLlHka3sIK9UVVPmlIBb2EF/FuSpks6OlzfJqX6fZ6kzyX9oqrncy6JvALe1STZfjN5HtgqqYige+/BwKgcznslUExwY/17ZnYU8Nvw2JjZUts+N/yxwJfACzmcz7lE8jngXU2R7WCyzcy2ELSLf9jMbgAOrMoJ0yrgjzez9eGqmUCLDLucCrxnZu9X5XzOJVVqBfyBBx5Iw4YNs66Ady5psr0Bv1lSX+BC4AfhsrpVOaFlmAM+dAnBAJMufRbGHfJ2KtF4rmiqu53K+vXrGT9+PMuXL6dRo0ace+65PPXUU/zsZz+r1vM4VwjZDiYXA1cAvzOz5ZIOB/5SXSEknUwwmJyUtnwPoDdw80729XYqVeS5oqnudhfTpk1jr732YtGiRQC0bduWZ599lhYttn9Br1evHuPHj6d9+/Zs3bqVTz/9lLfeeqtc4WJS23B4rmiSmitr2ZbKA/WANrmW3FtaOxWgI/Ae0DrDdmcSzMKY1XG9nUo0niua6s41c+ZMa9eunZWUlNi2bdvsggsusIceeqjcNoMHD7bLL7/czMxGjx5t5557bt5zVRfPFU2taKci6QfAPGBS+LlTdcwxIukQYCxwvpm9k2GTvmR5icu5XY1XwLuaJNvLXHcAxxH0yMLM5klqWQ3nvw3YF3g0/Nq+xcw6A0hqQPDE1+XVcB7nEskr4F1NkfUNeDP7LK3B3LaqntS2V8BfGr4ybVNCMNA455xLuGwHk0WSfgLsLqkVcA0wPX+xnHPO7UqyrTP5OdAe+IagWPEz4Bd5yuRcYi1dupROnTqVvfbZZx8eeOCBctuYGddccw1FRUV07NiRN954I56wzhVQpd9MJO0O/M3MTgZuiXJwSdcAA4A3gD8DDxDUp3xqZt9LO8ccYJWZnREuu5pgwDoCaGbla1Kci0WbNm2YN28eAFu3bqV58+acffbZ5bZ56aWXWLZsGcuWLWPWrFkMGDCAWbNmxZDWucKpdDAxs62StklqaGafRTz+lcBpwEaCy2I9zewDSfulbXctsATYJ2XZv4AXCW/6O5c0U6dO5YgjjuDQQw8tt3z8+PFccMEFSOKEE05gw4YNrFmzhgMPrFLTCOd2CdneM9kIvCXpZaCkdKGZXbOjHdLapowBxprZB+F+n6Rs14Jg7vffAf8v5dhvhuuz/Vm8Aj6i2pBrxaDTq+U4mYwZM4a+fftWWJ7aAgWgRYsWrFq1ygcTV6NlO5iMDV9Zs5S2KcBvgLqSpgHfAh40s5Hhpg8AN4bLI/MK+KqrDbmqs6I4tUJ58+bNPP/885xxxhkVzrF27VrefPNNtmwJfob169czd+5cNm7cWG1ZdpQrSTxXNEnNlbVcqx539iKsdAcGEzRybBB+Xga0Bs4AHg237Qa8uKNjZHM+r4CPxnNFk5pr3LhxVlxcnHG7/v3726hRo8o+t27d2lavXl2QXEniuaKpLRXwyyX9J/0VYcxaCUw2sxILbqS/DhxN0IK+t6QVBJfCTpH0VITjOheL0aNHZ7zEBdC7d29GjhyJmTFz5kwaNmzol7hcjZftZa7OKe/3As4FmkQ4z3hgsKQ6wB7A8cD9ZvYsYRNHSd2A683MW6a6RCspKeHll1/mscceK1s2ZMgQAK644gp69erFxIkTKSoqon79+jz55JNxRXWuYLIaTMwsfQKFByTNJWiHks3+SyRNAhYQVM4PNbOFO9snfKz4RuAAYIGkiWaWsVreuUJq0KBBhTlFrrjiirL3knjkkUcKHcu5WGU1mEg6JuXjbgTfVLJ5rPiwlPf3AvfuZNtppDwGbGYPAQ9lk88551y8sq2Avy/ldTdwDPDjfIVyLqm8At65zLK9Z3KJmZW74R5OkLVT2VTAh48PPwjsTnD5a1C4/GmCb0CbgdnA5Wa2Ocu8zuWFV8A7l1m230yey3JZuisJ2shfBTwK9Daz9gQ38EvbqDwCfB9oB/SV1C7c92ngSOAogom5/H6JS5SoFfDO1WQ7/WYi6UiCBo8NJf0wZdU+BE917WzfbCrgjwPeLf3WI2kMweyKi81sYsqxZgMtqIRXwEdTG3J5BbxzhVHZZa42BIWFjYAfpCz/ArhsZztadhXwzYEPU3ZbSfDYcBlJdYHzCfp3VeAV8FVXG3J5BXx8PFc0Sc2VtWwqG4ETq1IRSeUV8OcQ3Ccp3f58YHDaMf4MPJDN+bwCPhrPFY1XwEfjuaLZ1Svgs70B/6akqwgueZVd3jKzflnuvxJYa8HsiSWSSivgVwIHp2zXAlhV+kHS7UAzfOpelzCVVcAPHjyYPn36MGvWLK+Ad7VCtjfg/0JQPNgDeI3gl/4XEc4zHjhJUh1J9QkuZS0B/g20knS4pD2APsAEAEmXhufra2ZVniLYuepWWgH/wx9uv404ZMiQsir4Xr160bJlS4qKirjssst49NFH44rqXMFk+82kyMzOlXSmmY2QNAr4R7YnsZ1UwIeTYE0meDR4mJktCncbArwPzAjb0I81szuzPadz+eIV8M5VlO1gUlrfsUFSB+AjIH2Cqwosiwp4C57amphhebbZnHPOxSzby1yPS2oM3EpwGWoxcE/eUjmXUF4B71xmWQ0mZjbUzNab2Wtm1tLM9jOzIZXtJ+kaSUvCanYkdZG0RdI5advtI2mlpMEpy46V9JakdyU9pChTLjqXJ6UV8PPmzWPu3LnUr19/pxXwjz/+OAMGDIgprXOFk+18JvtLekLSS+HndpIuyWLXK4FiM/tpWO3+e2BKhu1+SzDHSao/EdSytApfPbPJ6lyheAW8c9tle5lrOMFN8oPCz+8Av9jZDqkV8JKuA34OPA98krbdscD+pAwykg4E9jGzmeEz0COBs7LM6lxBRK2Ad64my/Ymd1Mze0bSzQBmtkXS1p3tYOUr4PcERoXvu5RuI2k3gk7EPwNOS9m9OUENSqmV4bKd8nYq0dSGXPlqp7Jp0yYmTJjA3XffnZfjO7eryXYwKZG0L2AAkk4APotwngeAX5nZtrRbH1cCE81sZVVviXg7laqrDbny1U7ln//8J4cffjhLlixhyZIl5baTxOTJk8vaqSxbtoz333/f26kkhOfKk2zK5AnmL/kXwQDyL4LLXB2z2G8FQfuU5eH7FcBGgktdZxF0Bv4gXP4p8DkwCDgQeDvlOH2Bxyo7n7dTicZzRZOa67zzzrNhw4Zl3O7FF1+0nj172rZt22zGjBnWpUuXguVKEs8VTY1upyLpEDP7wMzekPQ9gsaPApZahLlFzKxs7hNJw4EXzWwcMC5l+UVAZzO7Kfz8efgNaBZwAfBwtudzLp98DnjnKqrsMtc4gm8lAH81sx/lN045VxLc+K9H0Mb+pQKe27kd8gp45yqqbDBJvZHRMurBLaUCPmXZRTvYdjjB4FH6eQ7QIeo5nXPOFV5ljwbbDt4755xzZSobTI4O7118AXQM338u6QtJnxcioHNJ4u1UnMtsp5e5zGz3XA4u6RpgAMFc7m8RXDb7AhhgZvMlHUxQkLg/wTefx83swbRj/BL4A9DMzD7NJY9zuSptpwKwdetWmjdvvtN2KrNmzWLAgAHMmjUrhrTOFU6+O/NeSVCMeAiwxMzWS/o+8DjBnCZbgF+GT4t9C5gr6WUzWwwQDjbdCR4fdi5RorZT8QmyXE2Wt8EktZ0KwTwl08NVMwkm18LM1gBrwvdfSFpCUOm+ONz2fuBGgsm1KuUV8NHUhlz5qoCH6O1UfDBxNVneBhNLaaeSdnnqEjI85ivpMODbBHUlSDoTWBVeDtvhebwCvupqQ658VcBv3ryZ559/njPOOKPCOdauXcubb75ZVgG/fv165s6d6xXwCeG58iTXqsedvQgr4FM+n0wwXe++advtDcwFfhh+rk8wqDTMdJwdvbwCPhrPFU1qrnHjxllxcXHG7fr372+jRo0q+9y6dWtbvXp1QXIlieeKZlevgM+2a3DOJHUEhgJnmtnalOV1CboJP21mY8PFRwCHA/MlrSC4LPaGpAMKlde5nRk9enTGS1wAvXv3ZuTIkZgZM2fOpGHDhn6Jy9V4BZkaV9IhwFjgfDN7J2W5gCcIbs7/sXS5mb1FyrTA4YDS2fxpLpcA3k7FuYoKNc/6bcC+wKPh/Y8tZtYZ+A5wPvCWpHnhtr+2YF545xLJ26k4V1FeBxPb3k7l0vCVvv6flG/ZUtlxnHPOJVDB7pk4VxN4BbxzmcUymEi6RtISSU+Hn7tI2iLpnJRtLpS0LHxdGEdO59KVVsDPmzePuXPnUr9+/Z1WwD/++OMMGDAgprTOFU6h7pmkuxI4zYIZFncHfk/5OeCbALcDnQnarMyVNMHM1seS1rkMvALeue0KPpikVsZLGkYwWDxPytzwQA/gZTNbF+7zMtATGL2zY3sFfDS1IZdXwDtXGAUfTCylMh7YExgVvk8dTJoDH6Z8Xhkuq8Ar4KuuNuTyCvj4eK5okpora7lWPVblxfa54Z8FTgiXDQfOCd9fD/wmZftbgesrO65XwEfjuaLxCvhoPFc0XgGfm87AmLAo8RyCOpSzgFXAwSnbtQiXOZcIXgHvXHlx3YAHwMwOL30vaTjwopmNC2/A3yWpcbi6O3BzDBGdq8Ar4J2rKNbBZEfMbJ2k3wL/DhfdaeHNeOfi5hXwzlUUy2BiGSrazeyitM/DgGEFiuSccy4Hcd8zcc45VwP4YOJcBN5OxbnMYrnMJekaYABwAEE9yTaC+eB/YWb/lHQo8ALBYFcXeNjMhsSR1blUpe1UALZu3Urz5s132k5l1qxZDBgwgFmzZsWQ1rnCibWdCrABKDEzCyfPegY4kmBe+BPN7BtJewMLw3Yqq2PK61wF3k7Fue1ibacCDDOz+8NVDQhaq2Bmm1J22ZMsL8d5O5VoakMub6fiXGHE2k7FzD6VdDZwN8HMimV/8iUdDPwNKAJu2NG3Em+nUnW1IZe3U4mP54omqbmylmsJfVVehO1U0pZ1Bf6eYduDgNnA/pUd19upROO5ovF2KtF4rmi8nUo1MbPXgZaSmqYtXw0sBL4bSzDnMvB2Ks6VF+tgIqlI4aTwko4huD+yVlILSfXC5Y2Bk4Cl8SV1brvSdio//OEPy5YNGTKkrKVKr169aNmyJUVFRVx22WU8+uijcUV1rmDibqfyI+ACSZuBr4DzzMwktQXuk2QEc8T/wczeijOoc6W8nYpzFcXdTuX34St9/ctAx0Jmcs45V3WJuWfiXD5t2LCBc845hyOPPJK2bdsyY8aMcuvNq9ady0leBxNJ10haIulpSd0kzZO0SNJrKdtcFy5bKGm0pL3C5U9LWhouHyapbj6zuprt2muvpWfPnrz99tvMnz+ftm3bllufWrX++OOPM2DAgJiSOrdryvc3kyuBYuAq4FGgt5m1B84FkNQcuAbobGYdgN2BPuG+TxNUwx8F1AMuzXNWV0N99tlnvP7661xyySUA7LHHHjRq1KjcNjuqWnfOZSdv90zSKt3HAGPN7AMAM/skLUO98CZ8fWB1uM3ElGPNJphtcae8Aj6apOYa3rNBtR5v+fLlNGvWjIsvvpj58+dz7LHH8uCDD9KgwfbzeNW6c7nJ22BiKZXuwG+AupKmAd8CHjSzkWa2StIfgA8InuaaYmZTUo8TXt46H7g203m8Ar7qkpqruiuBly5dyty5c7nooou46KKLePjhhxkwYAD9+vUr2yabqvWkVih7rmg8V57kWvW4sxdhpTswGJhJ0H+rKbAMaA00Bl4BmhF0Bx4H/CztGH8GHsjmfF4BH01tybVmzRo79NBDyz6//vrr1qtXr3LbZFO1Xlv+fVUXzxWNV8BnZyUw2cxKzOxT4HXgaILOwcvN7L9mthkYC/xP6U6Sbg8Hmv9XoJyuBjrggAM4+OCDWbo0qHudOnUq7dq1K7eNV607l5tC1ZmMBwZLqgPsARwP3E/wTeUESfUJLnOdCswBkHQp0AM41cy2FSinq6EefvhhfvrTn7Jp0yZatmzJk08+WVaxfsUVV9CrVy8mTpxIUVER9evX58knn4w5sXO7loIMJma2RNIkYAHBRFhDzWwhgKTngDcIJsd6E3g83G0I8D4wI+y4MtbM7ixEXlfzdOrUiTlz5pRb5lXrzlWfvA4mtr3SHTO7F7g3wza3A7dnWB53qxfnnHNZ8gp4Vyt4Bbxz+ZW3wSSl+v15STMkfSPp+rRtrg0r3BdJ+kXK8nPDZdskdc5XRld7eAW8c/mVz0tJpfO8bwIOBc5KXSmpA3AZcFy4zSRJL5rZuwTzl/wQeCyP+VwtUVoBP3z4cCCogN9jjz3KbePztjuXm7wMJpnmeZeUPhl3W2CWmX0Z7vMawQByj5ktCZdFOq9XwEeT1FxeAe/cricvg4mlzfO+g80WAr+TtC/BY8G9CB8LjsIr4Ksuqbm8Aj4azxWN58qTXKsed/QibZ534A7g+rRtLgHmEhQx/om0SndgGkETyKzO6RXw0dSWXF4BHw/PFY1XwOfAzJ4ws2PNrCuwHngnzjyuZvIKeOfyL9ZaDkn7mdknkg4huF9yQpx5XM3lFfDO5VfeBxNJBxDcC9kH2BY+AtzOzD4Hng/vmWwGrjKzDeE+ZwMPE/Tl+pukeWbWI99ZXc3lFfDO5Vc+W9AflvIx41wkZvbdHSx/AXghD7Gcc87lgVfAO+ecy5kPJq5W8HYqzuVXXgeTylqqSNpL0mxJ88P2KQNT1p0i6Y2w3cqIsH29c1Xi7VScy698/4LeaUsV4BvgFDPbGE7P+09JLwGzgREEc5m8I+lO4ELgiTzndTWQt1NxLv/yNphk01IlLJYpLTGuG74M2BfYZGaldScvAzdTyWDi7VSiSWoub6fi3K4nn09zZdNSBUm7E1TBFwGPmNksBU256kjqbGZzgHOAg3ewv7dTqaKk5vJ2KtF4rmg8V57kWkK/sxdZtFRJWdcIeBXoEH4+EfgHwSWv/wXmVXY+b6cSTW3J5e1U4uG5ovF2KtXEgoLFV4Ge4ecZZvZdMzuOoHeXt1pxVeLtVJzLv7jbqTQDNpvZBkn1gGLg9+G60lYrewK/An4XY1S3i/N2Ks7lV0EGkx21VAEOBEaE9012A54xsxfD3W6QdEa4/E9m9kohsrqaydupOJdfeR1MrPKWKguAb+9g3xuAG/IQyznnXDVLzD0T5/LJK+Cdy69YBpOUyvj1khZImidpjqSTUraZJGmDpBd3diznsuEV8M7lV1w34Esr4zcAJWZmkjoCzwBHhtvcC9QHLo8loasxvALeufwr+GCSqTI+XNWAoPodADObKqlblGN7BXw0Sc3lFfDO7XoKPphYWmV8OBHW3cB+wOk737sir4CvuqTm8gr4aDxXNJ4rT3KteqzKi7TK+HBZV+Dvacu6AS9me1yvgI+mtuTyCvh4eK5ovAK+mpjZ60BLSU3jzuJqFq+Ady7/4q6ALwLeMzOTdAywJ7A2zkyuZvIKeOfyK+4Jp34EXCBpM/AVcF74lQtJ/yB4smtvSSuBS8xscnxR3a7MK+Cdy69YBhPbXhn/+/CVaZvvFiyQc865nCTmnolz6Q477DCOOuooOnXqROfOnSusN69ady4x8jaYpFS5Py2pW1jlvkjSa+H6NuGy0tfnYQNIJJ0bbrtNUsXfIq7WePXVV5k3b16FS1TgVevOJUk+L3OVVrlvBKYDPc3sA0n7AZjZUqATlM22uAp4Idx3IfBD4LE85nO7OK9ady458jKYpFW5jwHGmtkHAGb2SYZdTiV4quv9cJsl4XEindcr4KOpzlwrBkWuN62UJLp3744kLr/8cvr3719uvVetO5cceRlMLKXKHfgNUFfSNOBbwINmNjJtlz7A6Kqcyyvgq646c1Vn5W5pJfA999xDs2bNWL9+Pddffz1fffUVRx99dNl22VStV6ekVih7rmg8V57kWvW4oxdhlTswGJhJ0HurKbAMaJ2y3R7Ap8D+GY4xDeic7Tm9Aj6aXSnX7bffbvfee2+5ZdlUrec7VxJ4rmg8V0XsIhXwK4HJZlZiZp8SzOd+dMr67wNvmNnHBcjidhElJSV88cUXZe+nTJlChw4dym3jVevOJUch6kzGA4Ml1SH4FnI8cH/K+r5U8RKXq7k+/vhjzj77bAC2bNnCT37yE3r27OlV684lVN4HEzNbImkSwRS924ChZrYQQFIDoJi0OUvCTsIPA82Av0maZ2Y98p3VJUfLli2ZP39+heVete5cMuVtMLGU+d/N7F6Cya7StykB9s2w/AW2PybsnHMu4bwC3jnnXM58MHHOOZczH0ycc87lzAcT55xzOfPBxDnnXM4UFD/WDJK+AJbGnSODpgRV/knjuaLxXNF4rmjizHWomTXL5QBxz7RY3ZaaWeJa1kua47my57mi8VzReK788MtczjnncuaDiXPOuZzVtMHk8bgD7IDnisZzReO5ovFceVCjbsA755yLR037ZuKccy4GPpg455zLWY0YTCT1lLRU0ruSboo7TylJB0t6VdJiSYskXRt3plKSdpf0pqQX486SSlIjSc9JelvSEkknxp0JQNJ14X/DhZJGS9orphzDJH0iaWHKsiaSXpa0LPxn44Tkujf877hA0guSGiUhV8q6X0oySU2TkkvSz8N/Z4sk3VPoXLnY5QcTSbsDjxDM2NgO6CupXbypymwBfmlm7YATgKsSlO1aYEncITJ4EJhkZkcSzMgZe0ZJzYFrCKaQ7gDsDvSJKc5woGfaspuAqWbWCpgafi604VTM9TLQwcw6Au8ANxc6FJlzIelgoDvwQaEDhYaTlkvSycCZwNFm1h74Qwy5qmyXH0yA44B3zew/ZrYJGEPwHyR2ZrbGzN4I339B8IuxebypQFIL4HRgaNxZUklqCHQFngAws01mtiHWUNvVAeqFM4bWB1bHEcLMXgfWpS0+ExgRvh8BnFXITJA5l5lNMbMt4ceZQIsk5ArdD9wIxPIE0g5yDQAGmdk34TafFDxYDmrCYNIc+DDl80oS8As7naTDgG8Ds2KOAvAAwR+kbTHnSHc48F/gyfAS3NBwNs5Ymdkqgr8lfgCsAT4zsynxpipnfzNbE77/CNg/zjA70A94Ke4QAJLOBFaZWcWpPOPVGviupFmSXpPUJe5AUdSEwSTxJO0NPA/8wsw+jznLGcAnZjY3zhw7UAc4BviTmX0bKCGeSzblhPcgziQY7A4CGkj6WbypMrPgWf9EPe8v6RaCS75PJyBLfeDXwG1xZ8mgDtCE4JL4DcAzkhRvpOzVhMFkFXBwyucW4bJEkFSXYCB52szGxp0H+A7QW9IKgkuCp0h6Kt5IZVYCK82s9NvbcwSDS9xOA5ab2X/NbDMwFvifmDOl+ljSgQDhPxNzeUTSRcAZwE8tGUVtRxD8pWB++GegBfCGpANiTRVYCYy1wGyCKwcFfzigqmrCYPJvoJWkwyXtQXBjdELMmQAI/1bxBLDEzP4Ydx4AM7vZzFqY2WEE/65eMbNE/C3bzD4CPpTUJlx0KrA4xkilPgBOkFQ//G96Kgl4MCDFBODC8P2FwPgYs5SR1JPgcmpvM/sy7jwAZvaWme1nZoeFfwZWAseE/+/FbRxwMoCk1sAeJLO7cUa7/GAS3uC7GphM8Af8GTNbFG+qMt8Bzif42/+88NUr7lAJ93PgaUkLgE7AXfHGgfCb0nPAG8BbBH9uYml9IWk0MANoI2mlpEuAQUCxpGUE36IGJSTXYOBbwMvh//tDEpIrdjvINQxoGT4uPAa4MCHf5rLi7VScc87lbJf/ZuKccy5+Ppg455zLmQ8mzjnncuaDiXPOuZz5YOKccy5ndeIO4NyuQNJWgseCS51lZitiiuNc4vijwc5lQdJGM9u7gOerk9Ik0bnE88tczlUDSQdKej0szlso6bvh8p6S3pA0X9LUcFkTSePCeT5mSuoYLr9D0l8k/Qv4i6Rmkp6X9O/w9Z0Yf0TndsovczmXnXqS5oXvl5vZ2WnrfwJMNrPfhXPs1JfUDPgz0NXMlktqEm47EHjTzM6SdAowkqDaH4I5eU4ys68kjQLuN7N/SjqEoMtD27z9hM7lwAcT57LzlZl12sn6fwPDwsae48xsnqRuwOtmthzAzErnrzgJ+FG47BVJ+0raJ1w3wcy+Ct+fBrRLaRy7j6S9zWxjdf1QzlUXH0ycqwZm9rqkrgSTjg2X9EdgfRUOVZLyfjfgBDP7ujoyOpdPfs/EuWog6VDgYzP7M8EMlscQzC7YVdLh4Tall7n+Afw0XNYN+HQH89xMIWh8WXqOTnmK71zO/JuJc9WjG3CDpM3ARuACM/uvpP7AWEm7EcwzUgzcQXBJbAHwJdvbx6e7Bngk3K4O8DpwRV5/CueqyB8Nds45lzO/zOWccy5nPpg455zLmQ8mzjnncuaDiXPOuZz5YOKccy5nPpg455zLmQ8mzjnncvb/AXVqfRLdXEHpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.barh(xgb_clf.feature_names, xgb_clf.feature_importances_)\n",
    "from xgboost import plot_importance\n",
    "plot_importance(xgb_clf, max_num_features =20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4e91c10e-6c1c-4d4e-a07c-5cba2bb5322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter = 1000, C = 0.05, class_weight = [1, 95]).fit(x_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "11d11fb2-fd5b-416d-b3a1-e1fc15a95998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "Precision: 0.80\n",
      "Recall: 0.76\n",
      "F1: 0.78\n",
      "g value is 0.9013565607802082 and d value is 0.6090353260869565\n",
      "0.7551959434335824\n"
     ]
    }
   ],
   "source": [
    "y_predict = logreg.predict(x_test_2)\n",
    "y_predict_proba = logreg.predict_proba(x_test_2)[:,1]\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test_2, y_predict)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test_2, y_predict)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test_2, y_predict)))\n",
    "print('F1: {:.2f}'.format(f1_score(y_test_2, y_predict)))\n",
    "print(amex_metric(pd.DataFrame(y_test_2), pd.DataFrame(y_predict_proba, index = y_test_2.index, columns = ['prediction'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f7b79b94-d8dc-4f4f-80a3-4934e70fe141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "#logreg_2 = LogisticRegression(max_iter = 1000)\n",
    "#grid_values = {'C': [0.1, 0.5, 1, 10],\n",
    "#               'class_weight' : ['balanced', None]}\n",
    "\n",
    "# default metric to optimize over grid parameters: accuracy\n",
    "#grid_clf_acc = GridSearchCV(logreg_2, param_grid = grid_values)\n",
    "#grid_clf_acc.fit(x_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b37487a-a595-4557-bf6e-41b5a7f29c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svcrbf = SVC(kernel = 'rbf', probability = True).fit(x_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b2a9a-3c49-4551-946d-682c98e7757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = svcrbf.predict(x_test_2)\n",
    "y_predict_proba = svcrbf.predict_proba(x_test_2)[:,1]\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(y_test_2, y_predict)))\n",
    "print('Precision: {:.2f}'.format(precision_score(y_test_2, y_predict)))\n",
    "print('Recall: {:.2f}'.format(recall_score(y_test_2, y_predict)))\n",
    "print('F1: {:.2f}'.format(f1_score(y_test_2, y_predict)))\n",
    "print(amex_metric(pd.DataFrame(y_test_2), pd.DataFrame(y_predict_proba, index = y_test_2.index, columns = ['prediction'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6b2e0b7-b479-4c54-80ee-48792b40143d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52e0c348-cf01-4083-8b0c-95d5bb861953",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_data = pd.read_parquet('C:/Users/DavidG/Documents/american_express_data/data_1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e89d872-ad57-4059-9202-40292b777a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/DavidG/Documents/american_express_data/data_2.parquet'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'C:/Users/DavidG/Documents/american_express_data/data_{}.parquet'.format(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "feacaf55-3466-42f5-ba64-53c7cacfbcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_mean</th>\n",
       "      <th>P_2_amax</th>\n",
       "      <th>P_2_amin</th>\n",
       "      <th>P_2_std</th>\n",
       "      <th>D_39_mean</th>\n",
       "      <th>D_39_amax</th>\n",
       "      <th>D_39_amin</th>\n",
       "      <th>D_39_std</th>\n",
       "      <th>B_1_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>D_131</th>\n",
       "      <th>D_133</th>\n",
       "      <th>R_28</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000d17a1447b25a01e42e1ac56b091bb7cbb06317be4c...</td>\n",
       "      <td>1.005816</td>\n",
       "      <td>1.009762</td>\n",
       "      <td>1.000488</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>0.353440</td>\n",
       "      <td>0.560899</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.215033</td>\n",
       "      <td>0.062956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>0.002260</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001337ded4e1c2539d1a78ff44a457bd4a95caa55ba17...</td>\n",
       "      <td>0.374289</td>\n",
       "      <td>0.612548</td>\n",
       "      <td>0.254523</td>\n",
       "      <td>0.206339</td>\n",
       "      <td>0.084755</td>\n",
       "      <td>0.241415</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.135677</td>\n",
       "      <td>0.108588</td>\n",
       "      <td>...</td>\n",
       "      <td>2.003728</td>\n",
       "      <td>1.107959</td>\n",
       "      <td>0.016179</td>\n",
       "      <td>1.998605</td>\n",
       "      <td>0.013047</td>\n",
       "      <td>1.956557</td>\n",
       "      <td>1.997741</td>\n",
       "      <td>0.016679</td>\n",
       "      <td>0.283608</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001812036f1558332e5c0880ecbad70b13a6f28ab04a8...</td>\n",
       "      <td>0.386107</td>\n",
       "      <td>0.431697</td>\n",
       "      <td>0.340604</td>\n",
       "      <td>0.031185</td>\n",
       "      <td>0.117855</td>\n",
       "      <td>0.354380</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.134075</td>\n",
       "      <td>0.862294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.003137</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00039533fe0b61bcf1ec0d1aefe6acb5469ea0f0d1b0ad...</td>\n",
       "      <td>0.247794</td>\n",
       "      <td>0.313965</td>\n",
       "      <td>0.150654</td>\n",
       "      <td>0.053293</td>\n",
       "      <td>0.025080</td>\n",
       "      <td>0.093875</td>\n",
       "      <td>0.003542</td>\n",
       "      <td>0.024725</td>\n",
       "      <td>0.602409</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0003e58375faf90552b2861c1ccea4ee5757827cbb6ecd...</td>\n",
       "      <td>0.825571</td>\n",
       "      <td>0.839217</td>\n",
       "      <td>0.776110</td>\n",
       "      <td>0.018486</td>\n",
       "      <td>0.113482</td>\n",
       "      <td>0.564188</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.198287</td>\n",
       "      <td>0.014267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.002356</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0.002637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114724</th>\n",
       "      <td>fffc9005dae01b2c79a168c6562144220657b28b8f1bf4...</td>\n",
       "      <td>0.746232</td>\n",
       "      <td>0.755517</td>\n",
       "      <td>0.723696</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>0.004974</td>\n",
       "      <td>0.009215</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114725</th>\n",
       "      <td>fffdc0cf228085b4275b38ebe6eb915766af3fecb2ae28...</td>\n",
       "      <td>0.964291</td>\n",
       "      <td>0.994921</td>\n",
       "      <td>0.886337</td>\n",
       "      <td>0.032537</td>\n",
       "      <td>0.246970</td>\n",
       "      <td>0.591984</td>\n",
       "      <td>0.001412</td>\n",
       "      <td>0.199295</td>\n",
       "      <td>0.044627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002712</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114726</th>\n",
       "      <td>fffee847c5c1af7dbdd36d98fea882893256c422cde86c...</td>\n",
       "      <td>0.726345</td>\n",
       "      <td>0.885434</td>\n",
       "      <td>0.629187</td>\n",
       "      <td>0.093502</td>\n",
       "      <td>0.008404</td>\n",
       "      <td>0.039272</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.013202</td>\n",
       "      <td>0.012062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114727</th>\n",
       "      <td>fffef3305f19a11fb6c15f4ebe9be1bd664540e57c0a6a...</td>\n",
       "      <td>0.304604</td>\n",
       "      <td>0.370313</td>\n",
       "      <td>0.229116</td>\n",
       "      <td>0.044657</td>\n",
       "      <td>0.143390</td>\n",
       "      <td>0.361938</td>\n",
       "      <td>0.088934</td>\n",
       "      <td>0.082065</td>\n",
       "      <td>0.576485</td>\n",
       "      <td>...</td>\n",
       "      <td>0.460551</td>\n",
       "      <td>0.135116</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114728</th>\n",
       "      <td>ffff39cc22a375d07369980d02d617883dd28ad81a6aa3...</td>\n",
       "      <td>0.770611</td>\n",
       "      <td>0.797892</td>\n",
       "      <td>0.736329</td>\n",
       "      <td>0.021340</td>\n",
       "      <td>0.036040</td>\n",
       "      <td>0.215072</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>0.055718</td>\n",
       "      <td>0.101614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.002838</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114729 rows × 751 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              customer_ID  P_2_mean  P_2_amax  \\\n",
       "0       0000d17a1447b25a01e42e1ac56b091bb7cbb06317be4c...  1.005816  1.009762   \n",
       "1       0001337ded4e1c2539d1a78ff44a457bd4a95caa55ba17...  0.374289  0.612548   \n",
       "2       0001812036f1558332e5c0880ecbad70b13a6f28ab04a8...  0.386107  0.431697   \n",
       "3       00039533fe0b61bcf1ec0d1aefe6acb5469ea0f0d1b0ad...  0.247794  0.313965   \n",
       "4       0003e58375faf90552b2861c1ccea4ee5757827cbb6ecd...  0.825571  0.839217   \n",
       "...                                                   ...       ...       ...   \n",
       "114724  fffc9005dae01b2c79a168c6562144220657b28b8f1bf4...  0.746232  0.755517   \n",
       "114725  fffdc0cf228085b4275b38ebe6eb915766af3fecb2ae28...  0.964291  0.994921   \n",
       "114726  fffee847c5c1af7dbdd36d98fea882893256c422cde86c...  0.726345  0.885434   \n",
       "114727  fffef3305f19a11fb6c15f4ebe9be1bd664540e57c0a6a...  0.304604  0.370313   \n",
       "114728  ffff39cc22a375d07369980d02d617883dd28ad81a6aa3...  0.770611  0.797892   \n",
       "\n",
       "        P_2_amin   P_2_std  D_39_mean  D_39_amax  D_39_amin  D_39_std  \\\n",
       "0       1.000488  0.003309   0.353440   0.560899   0.000811  0.215033   \n",
       "1       0.254523  0.206339   0.084755   0.241415   0.005258  0.135677   \n",
       "2       0.340604  0.031185   0.117855   0.354380   0.000871  0.134075   \n",
       "3       0.150654  0.053293   0.025080   0.093875   0.003542  0.024725   \n",
       "4       0.776110  0.018486   0.113482   0.564188   0.001599  0.198287   \n",
       "...          ...       ...        ...        ...        ...       ...   \n",
       "114724  0.723696  0.009455   0.004974   0.009215   0.000739  0.003228   \n",
       "114725  0.886337  0.032537   0.246970   0.591984   0.001412  0.199295   \n",
       "114726  0.629187  0.093502   0.008404   0.039272   0.000581  0.013202   \n",
       "114727  0.229116  0.044657   0.143390   0.361938   0.088934  0.082065   \n",
       "114728  0.736329  0.021340   0.036040   0.215072   0.003508  0.055718   \n",
       "\n",
       "        B_1_mean  ...     D_131     D_133      R_28     D_139     D_140  \\\n",
       "0       0.062956  ...  0.002532  0.002378  0.003190  0.002260  0.002570   \n",
       "1       0.108588  ...  2.003728  1.107959  0.016179  1.998605  0.013047   \n",
       "2       0.862294  ...  0.002099  0.001926  0.002715  0.002453  0.002428   \n",
       "3       0.602409  ...  0.001975  0.002823  0.002838  0.002664  0.002145   \n",
       "4       0.014267  ...  0.002905  0.002770  0.001816  0.002356  0.002720   \n",
       "...          ...  ...       ...       ...       ...       ...       ...   \n",
       "114724  0.004776  ...  0.002444  0.002751  0.002757  0.002368  0.001774   \n",
       "114725  0.044627  ...  0.002712  0.002248  0.002633  0.002179  0.002513   \n",
       "114726  0.012062  ...  0.001576  0.001538  0.002466  0.002321  0.001993   \n",
       "114727  0.576485  ...  0.460551  0.135116  0.002146  0.002262  0.003207   \n",
       "114728  0.101614  ...  0.001744  0.002238  0.002384  0.002944  0.001816   \n",
       "\n",
       "           D_141     D_143     D_144     D_145  target  \n",
       "0       0.002070  0.002356  0.002590  0.002924       0  \n",
       "1       1.956557  1.997741  0.016679  0.283608       1  \n",
       "2       0.003137  0.002443  0.002132  0.001712       1  \n",
       "3       0.002585  0.001890  0.002043  0.002612       1  \n",
       "4       0.003437  0.002564  0.002707  0.002637       0  \n",
       "...          ...       ...       ...       ...     ...  \n",
       "114724  0.002850  0.002961  0.002914  0.002407       0  \n",
       "114725  0.002908  0.002061  0.003014  0.002562       0  \n",
       "114726  0.003453  0.002695  0.002955  0.003103       0  \n",
       "114727  0.002761  0.002565  0.002018  0.002984       0  \n",
       "114728  0.002838  0.001899  0.002989  0.002648       0  \n",
       "\n",
       "[114729 rows x 751 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2113fa-fcf1-44b2-a2c7-f3f20a86d9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
